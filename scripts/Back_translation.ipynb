{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtxlqhfjZ/JupLubl3hLc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianshuailu/NMT-Adapt_ml_IN/blob/main/scripts/Back_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Back translation with transliterated Malayalam**\n",
        "\n",
        "We used transliterated Malayalam as source language, but still have to use hi_IN as the language label to let the pretrained model to translate it into English.\n",
        "\n",
        "Both of the dictionary files should be the same as the dictionary used for pretraining mBART."
      ],
      "metadata": {
        "id": "amckoov9msKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess \\\n",
        "--source-lang hi_IN \\\n",
        "--target-lang en_XX \\\n",
        "--only-source \\\n",
        "--srcdict /your_path/dict.txt \\\n",
        "--tgtdict /your_path/dict.txt \\\n",
        "--testpref /your_path/train.spm \\\n",
        "--destdir /your_path/bt \\\n",
        "--workers 70 "
      ],
      "metadata": {
        "id": "-e_O7sYomkKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we used fairseq-generate to generate the back translation pairs"
      ],
      "metadata": {
        "id": "O6j4JpOs0auQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-generate /your_path/bt \\\n",
        "  --path /your_path/pretrained_model.pt \\\n",
        "  --results-path /your_path/result \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --gen-subset test \\\n",
        "  -t en_XX -s hi_IN \\\n",
        "  --scoring sacrebleu \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model /your_path/sentence.bpe.model \\\n",
        "  --scoring sacrebleu \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,ml_XX,no_ML,no_HI"
      ],
      "metadata": {
        "id": "haQTU_Liv0qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we used the following commands to extract the sentences from the fairseq generated file."
      ],
      "metadata": {
        "id": "Zb_HJkN3u12x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat generate-test.txt | grep -P \"^S\" |sort -V |cut -f 2- | sed 's/\\[en_XX\\]//g' > bt.en_XX\n",
        "!cat generate-test.txt | grep -P \"^H\" |sort -V |cut -f 3- | sed 's/\\[ml_XX\\]//g' > bt.ml_XX"
      ],
      "metadata": {
        "id": "lcovLuUouxUu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}