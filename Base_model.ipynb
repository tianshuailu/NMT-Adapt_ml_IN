{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "For the base model, we used Malayalam sentences transliterated to Hindi and parallel data to train a pre-trained mBart.cc25 model. We conducted 20 experiments with 1,000 to 20,000 parallel sentences in increments of 1,000 as training data and Workshop on Asian Translation 2021 (wat2021) benchmark data for English and Malayalam for final testing and validation."
      ],
      "metadata": {
        "id": "_2Fl8j4h9HWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing and pre-training\n",
        "\n",
        "We follow the same steps as NMT-Adapt for pre-processing the data, trimming the mBart.cc25 model and pre-training it using fairseq and sentencepiece."
      ],
      "metadata": {
        "id": "dYpxLiOB8JlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "After pre-training the model, training was done for each experiment as below:"
      ],
      "metadata": {
        "id": "HHKxqmOw8-O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuHumc-E7Nt8"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "\n",
        "fairseq-train /your_path/data --encoder-normalize-before --decoder-normalize-before --arch mbart_large --layernorm-embedding\n",
        "--task translation_from_pretrained_bart --source-lang en_XX --target-lang hi_IN --criterion label_smoothed_cross_entropy\n",
        "--label-smoothing 0.2 --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9,0.98)' --lr-scheduler polynomial_decay --lr 3e-05\n",
        "--warmup-updates 2500 --total-num-update 40000 --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 --max-tokens 1024\n",
        "--update-freq 2 --save-interval 1 --save-interval-updates 5000 --keep-interval-updates 10 --no-epoch-checkpoints --seed 222\n",
        "--log-format simple --log-interval 2 --restore-file /your_path/pretrained_model.pt --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler\n",
        "--langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\n",
        "--save-dir /your_path/checkpoint --ddp-backend no_c10d --max-epoch 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "We used the following command for model evaluation:"
      ],
      "metadata": {
        "id": "l9ae1A9MCs2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fairseq-generate /your_path/data --path /your_path/checkpoint_best.pt --results-path /your_path/eval_result --task translation_from_pretrained_bart\n",
        "--gen-subset test -t hi_IN -s en_XX --bpe 'sentencepiece' --sentencepiece-model --sentencepiece-model /your_path/sentence.bpe.model --scoring sacrebleu\n",
        "--remove-bpe 'sentencepiece' --batch-size 32\n",
        "--langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN"
      ],
      "metadata": {
        "id": "W1CUr66SC619"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}